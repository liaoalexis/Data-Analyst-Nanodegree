{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reporting: Wrangle_report\n",
    "* Create a **300-600 word written report** called \"wrangle_report.pdf\" or \"wrangle_report.html\" that briefly describes your wrangling efforts. This is to be framed as an internal document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project's purpose was to wrangle WeRateDogs Twitter data in order to make engaging and trustworthy analysis and visualisations. The challenge was in the fact that the Twitter archive was great, but it only contained very basic tweet information. Additional gathering, assessing, and cleaning was required to achieve the desired outcomes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Gathering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Three pieces of data were gathered for this project:**\n",
    "\n",
    "- **Twitter archive data** (twitter_archive_enhanced.csv) was downloaded directly.\n",
    "- **tweet image predictions** (image_predictions.tsv) were downloaded programmatically using the Requests library from a provided URL.\n",
    "- **Additional data**, such as retweet count and favorite count, were gathered using the Tweepy library to query the Twitter API (tweet_json.txt). However, since the Twitter API access was not granted, the tweet-json.txt file was downloaded directly and parsed to extract the relevant data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Assessing\n",
    "\n",
    "The data was assessed both visually and programmatically to identify quality and tidiness issues. In total, eight quality issues and two tidiness issues were identified."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quality Issues\n",
    "\n",
    "**Twitter Archive Table**\n",
    "- Timestamp column was in string format instead of datetime.\n",
    "- The dataset contained 181 retweets and 78 replies, which were not needed for the analysis.\n",
    "- Missing values in the expanded_urls column.\n",
    "- Extreme numbers in rating denominators, with 23 denominators not being 10.\n",
    "- Extreme numbers in rating numerators.\n",
    "- Some dogs' names were invalid (e.g., None, a, such, etc.).\n",
    "\n",
    "**Image Predictions Table**\n",
    "- Some photos were not identified as dogs (e.g., orange, bagel, banana), with p#_dog = False.\n",
    "- Inconsistent capitalization in names of dog breeds.\n",
    "\n",
    "### Tidiness Issues\n",
    "- Dog stage data in the tweet archive table was divided into columns doggo, floofer, pupper, and puppo.\n",
    "- Some columns related to analysis in the image predictions and tweet JSON tables needed to be merged into the main archive table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "\n",
    "Before cleaning the data, copies of the original datasets were created. Each identified issue was then addressed one by one, following the Define-Code-Test cycle.\n",
    "\n",
    "- Retweets and replies were removed from the dataset, and the corresponding columns were dropped.\n",
    "- The timestamp column's data type was converted to datetime.\n",
    "- Rows with missing values in the expanded_urls column were dropped.\n",
    "- Invalid dog names were replaced with 'None'.\n",
    "- A new column 'dog_stage' was created to consolidate the four separate dog stage columns.\n",
    "- Rating numerators and denominators were extracted from the text, and extreme values were adjusted accordingly.\n",
    "- The highest confidence prediction for dog breeds was used to create a 'breed' column, and photos not identified as dogs were filtered out.\n",
    "- The capitalization in the names of dog breeds was normalized.\n",
    "\n",
    "Finally, the cleaned datasets were merged into a single, tidy master dataset for further analysis and visualization.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Data wrangling is an important step in the data analysis process. It involves gathering, assessing, and cleaning data to ensure that it is both high-quality and tidy. Multiple datasets were obtained from various sources and formats for this project, analyzed for quality and tidiness issues, and cleaned accordingly. The clean dataset that resulted allowed for the production of informative analysis and visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
